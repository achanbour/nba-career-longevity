---
title: "NBA Career Longevity Prediction"
author: "12345, 56789, 26183"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)

#library(tidyverse)
library(kableExtra)
library(tree)
#library(broom) # tidymodels
library(caret)
#library(dplyr) # tidymodels
#library(ggplot2) # tidymodels
#library(fastDummies) # pivot_wider 
# library(corrplot) # possibly not doing a corr plot
library(prettydoc)
library(tidymodels)

raw_data <- read.csv("data_in/nba_logreg.csv")
```

# I: Project Introduction

This dataset contains the key performance metrics of NBA players in their rookie (first) season in the NBA League and additional information about how they entered the league (The NBA Draft and the teams they were drafted to).

The objective of this project is to build some classification models to predict whether or not players will play at least 5 years in the NBA, given how they performed in their rookie season. Given the term structure of rookie contracts, players who make it to year 5 have a higher chance of getting another contract and playing several more years.

This dataset was collected from https://data.world/exercises/logistic-regression-exercise-1

Additional data regarding the year players were drafted, what round they were drafted in, the year they debuted, the team they played for and that team's record at the end of the season was web scraped from Wikipedia using a Python script not included in this document.

Before being web scraped, the dataset was checked for repeated values and missing values, typos and errors. The data was validated using https://www.basketball-reference.com/ ???

## Variable descriptions

### Outcome
**TARGET_5Yrs**: Dummy variable, with value 1 for players who went on to play 5 or more years in the league, and 0 for those that did not


### Predictors
  1) **GP**	- Games played		
  2) **MIN**	- Minutes played		
  3) **PTS**	- Points per game		
  4) **FGM**	- Field goals made		
  5) **FGA**	- Field goal attempts		
  6) **FG%**	- Field goal percent		
  7) **3P Made** - Three-pointers made		
  8) **3PA**	- Three-pointers attempted		
  9) **3P%**	- Three-point attempt percentage?		
  10) **FTM**	- Free throws made		
  11) **FTA**	- Free throws attempted		
  12) **FT%**	- Free throw percent?		
  13) **OREB**	- Offensive rebounds		
  14) **DREB**	- Defensive rebounds		
  15) **REB**	- Rebounds		
  16) **AST**	- Assists		
  17) **STL**	- Steals		
  18) **BLK**	- Blocks		
  19) **TOV**	- Turnovers		
  20) **Year_Drafted** - 			
  21) **Round_Drafted**	- 		
  22) **Team**	- Team played for		
  23) **Win_Perc**	- Win percentage		
  24) **Position**	- Poisition		
  25) **Year_Debut**	

## Preview raw data
```{r}
kable(head(raw_data)) # %>%
#  kable_styling(bootstrap_options = c("striped", "bordered", "hover", "condensed", "responsive")) 
# # scroll_box(width = "800px")

glimpse(raw_data)
```

# II: Exploratory Data Analysis (EDA) of raw data

## Summary statistics

Using the powerful "summary" function, we can check each column for missing, negative (where there shouldn't be), infinite and anomalous values. We can also make sure all values fall within the expected ranges for particular variables (year drafted, win percentage etc.), using the minimum and maximum statistics. 

```{r}
summary(raw_data)
```

**Insights:**

  1) The character variables, name, round drafted, team and position, all have the expected number of observations (1301).
  2) Values for year drafted and year debut are all in the expected range (between 1971 and 2016)
  3) Values for win percentage are all between 0 and 1, as expected
  4) TARGET_5Yrs takes values between 0 and 1, with a mean of 0.6287, implying 62.87% (818) of the players reached 5 years, and 37.13% (483) did not
  
5) A small number of NAs are present in the expected 3 pointers and win percentage columns (10 and 1 respectively). Given this is less than 1% of the sample size, we make the decision to drop observations with a missing value for any variable, as it will make the model-fitting easier while costing very little in accuracy:

```{r}
data <- na.omit(raw_data) 
sprintf("NAs omitted, number of obs falls from %s to %s", nrow(raw_data), nrow(data))
```

## Correlations between regressors and outcome variable

As a simple way to get a sense of which of the numeric regressors are most likely to be have predictive power, we take the correlation coefficient of each numeric regressor with the outcome variable (TARGET_5Yrs)

```{r}
kable(round(cor(data$TARGET_5Yrs, Filter(is.numeric, data)),2)) # round to 2 d.p. and pretty-print
```

```{r corrplot}



# corr_matrix = cor(Filter(is.numeric, raw_data))
# corrplot(corr_matrix , type = "upper", tl.col = "black" , tl.srt = 45)

```

## Distributions of numeric variables, by outcome

```{r, fig.height= 10, fig.width = 10, warning=FALSE}
raw_numerics_long <- Filter(is.numeric, raw_data) %>% 
  pivot_longer(!TARGET_5Yrs, names_to = "variable", values_to = "value")
raw_numerics_long$TARGET_5Yrs <- as.character(raw_numerics_long$TARGET_5Yrs)

ggplot(raw_numerics_long, aes(value, fill = TARGET_5Yrs)) + geom_boxplot() + facet_wrap(~variable, scales = "free") + labs(x = "")
ggplot(raw_numerics_long, aes(value, fill = TARGET_5Yrs)) + geom_histogram() + facet_wrap(~variable, scales = "free") + labs(x = "")
```

We see that for most variables, the distribution of values for players who went on to succeed is higher. This makes sense, as most of these variables are increasing in player quality (the better player is expected to make more blocks, steals etc.) 

## Distributions of categoric variables, by outcome

```{r}
# raw_categorics_long <- raw_data %>% 
#   select(TARGET_5Yrs, Round_Drafted, Team, Position) %>%
#   pivot_longer(!TARGET_5Yrs, names_to = "variable", values_to = "value") %>% 
#   group_by(variable, value, TARGET_5Yrs) %>% 
#   summarise(sum = n())
# 
# raw_categorics_long$TARGET_5Yrs <- as.character(raw_categorics_long$TARGET_5Yrs)
# 
# bar_chart <- ggplot(raw_categorics_long, aes(sum, fill = value)) + geom_bar() + facet_wrap(~variable, scales = "free")  
# 
# bar_chart

bar_plot = function(variable){
  data <- raw_data[,c("TARGET_5Yrs",variable)] 
  colnames(data)[2] = "variable"
  data <- data %>%
    group_by(TARGET_5Yrs, variable) %>%
    tally()
  
  data$TARGET_5Yrs <- as.character(data$TARGET_5Yrs)
#  data$var <- as.character(data$var)
  
  print(data %>% ggplot(aes(x = variable , y = n , fill = TARGET_5Yrs))+
    geom_bar(stat = "identity", width = 0.4, position = position_dodge(width = 0.5)))
}

variables = c("Round_Drafted","Team","Position")

for (i in variables){
  bar_plot(i)
}  


  
```


# III: Pre-process dataset

### Create indicator variables

Using tidymodels "step_dummy_multi_choice" function, create dummy columns for the three categoric variables (Team, Round Drafted and Position)

```{r, warning=FALSE}
# data_to_split <- data %>% 
#   mutate(n = 1) %>% 
#   pivot_wider(names_from = Round_Drafted, values_from = n,
#               names_prefix = 'round_drafted_', values_fill = list(n = 0)) %>% 
#   mutate(n = 1) %>% 
#   pivot_wider(names_from = Position, values_from = n,
#               names_prefix = 'position_', values_fill = list(n = 0))

dummy_multi_choice_rec <- recipe(~ ., data = data) %>%
  step_dummy(Team) %>%
  step_dummy(Position) %>%
  prep()

data_to_split <- bake(dummy_multi_choice_rec, new_data = data)
#ids <- tidy(dummy_multi_choice_rec, number = 1)

kable(head(data_to_split))
glimpse(data_to_split)
```

### Split dataset into training and testing

Using tidymodels "initial_split" function, split data into training and testing, using (the default) 75% of observations for training and 25% for testing.

```{r}
set.seed(1423)
data_split <- initial_split(data_to_split)

data_training <- data_split %>%
  training()

data_testing <- data_split %>%
  testing()

sprintf("Data had %s obs, now split into training (%s obs) and testing (%s obs)", nrow(data), nrow(data_training), nrow(data_testing))
```
